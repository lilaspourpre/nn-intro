{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Что такое нейронные сети?\n",
    "\n",
    "\n",
    "![title](img/nss.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Для чего нужны нейронные сети?\n",
    "\n",
    "* Классификация — распределение данных по параметрам. Например, на вход дается набор людей и нужно решить, кому из них давать кредит, а кому нет. Эту работу может сделать нейронная сеть, анализируя такую информацию как: возраст, платежеспособность, кредитная история и тд.\n",
    "\n",
    "![title](img/class.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Предсказание — возможность предсказывать следующий шаг. Например, рост или падение акций, основываясь на ситуации на фондовом рынке.\n",
    "\n",
    "![title](img/regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Распознавание — в настоящее время, самое широкое применение нейронных сетей. Используется в Google, когда вы ищете фото или в камерах телефонов, когда оно определяет положение вашего лица и выделяет его и многое другое.\n",
    "\n",
    "![title](img/face.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Как устроены нейросети\n",
    "\n",
    "![title](img/ex.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что такое синапс?\n",
    "\n",
    "![title](img/sin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![title](img/ex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Функции активации\n",
    "![title](img/fa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Что такое тренировочный сет?\n",
    "\n",
    "![title](img/batch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Что такое итерация\n",
    "\n",
    "Прохождение одного батча по графу нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Что такое эпоха\n",
    "\n",
    "Прохождение всех батчей тренировочных данных по графу сети ровно один раз\n",
    "\n",
    "Количество пройденных раз = количество эпох\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Как сделать чтобы НС давала правильные ответы?\n",
    "\n",
    "Нужно ее обучать!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](img/train.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ошибка/потери (loss)\n",
    "\n",
    "Разница между выходом нейронной сети и правильным ответом\n",
    "\n",
    "![title](img/error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Метод обратного распространения (Backpropagation)\n",
    "\n",
    "![title](img/gif.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Скорость обучения или Learning rate\n",
    "\n",
    "![title](img/lyz.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Что еще нужно учитывать?\n",
    "\n",
    "\n",
    "* Количество скрытых слоев\n",
    "* Количество нейронов в каждом слое\n",
    "* Сходимость\n",
    "* Переобучение (dropout)\n",
    "\n",
    "![title](img/conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сеть прямого распространения  для классификации текстов\n",
    "\n",
    "\n",
    "![title](img/mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Давайте попробуем что-то сделать сами!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array([\n",
    "        [1.0, 1.0, 1.0, 0.0, 1.0, 0.0],\n",
    "        [1.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
    "        [0.0, 1.0, 1.0, 1.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 1.0, 1.0, 1.0],\n",
    "        [0.0, 0.0, 1.0, 1.0, 1.0, 1.0],\n",
    "        [0.0, 0.0, 0.0, 1.0, 1.0, 1.0],\n",
    "        [0.0, 1.0, 0.0, 1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "y_train_array = [1, 1, 1, 0, 0, 0, 0, 1]\n",
    "y_train = keras.utils.to_categorical(np.array(y_train_array), num_classes=2)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "batch_size=2\n",
    "nb_epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=6, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=nb_epoch, batch_size=batch_size, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_train)\n",
    "print(classification_report(y_train_array, y_pred))\n",
    "labels = [1,0]\n",
    "sns.heatmap(data=confusion_matrix(y_train_array, y_pred, labels = labels), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [1.0, 1.0, 1.0, 0.0, 0.0, 1.0],\n",
    "        [1.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 1.0],\n",
    "        [0.0, 1.0, 1.0, 1.0, 0.0, 1.0],\n",
    "        [0.0, 0.0, 0.0, 1.0, 0.0, 1.0]])\n",
    "\n",
    "y_test_array = [1, 1, 1, 0, 0, 0]\n",
    "y_test = keras.utils.to_categorical(np.array(y_test_array), num_classes=2)\n",
    "\n",
    "y_result = model.predict_classes(X_test)\n",
    "print(classification_report(y_test_array, y_result))\n",
    "labels = [1,0]\n",
    "sns.heatmap(data=confusion_matrix(y_test_array, y_result, labels = labels), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Какие еще нейросети бывают?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Сверточные нейронные сети\n",
    "\n",
    "![title](img/cnn6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![title](img/convol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![title](img/cnn1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![title](img/cnn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![title](img/cnn3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![title](img/cnn4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Рекуррентные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![title](img/RNN-rolled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![title](img/RNN-unrolled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![title](img/LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Seq2seq-архитектура"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![title](img/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/seq2seq2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Механизм внимания\n",
    "\n",
    "![](img/decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Попробуем сделать свой seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import helper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conversations.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences_list = f.readlines()\n",
    "sentences = [re.sub(\"^- \", \"\", i) for i in sentences_list if i != \"\"]\n",
    "dataset, id2word, word2id, MAX_LEN = helper.prepare_for_dataset(sentences)\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "DECODER_SIZE = 256\n",
    "EMBEDDING_SIZE = 100\n",
    "VOCABULARY_SIZE = len(id2word)\n",
    "WORD_DIM = 300\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(num):\n",
    "    result = [0] * VOCABULARY_SIZE\n",
    "    result[num] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 13, 100)      17800       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 13, 100)      17800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 365568      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 13, 256), (N 365568      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 13, 178)      45746       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 812,482\n",
      "Trainable params: 812,482\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# SEQ2SEQ model\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(MAX_LEN,))\n",
    "embeddings = Embedding(input_dim=VOCABULARY_SIZE, output_dim=EMBEDDING_SIZE)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = LSTM(HIDDEN_SIZE, return_state=True)(embeddings)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(MAX_LEN,))\n",
    "decoder_embeddings_inputs = Embedding(VOCABULARY_SIZE, EMBEDDING_SIZE)(decoder_inputs)\n",
    "decoder_lstm = LSTM(DECODER_SIZE, return_sequences=True, return_state=True)\n",
    "decoder_output, _, _ = decoder_lstm(decoder_embeddings_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(VOCABULARY_SIZE, activation='softmax')\n",
    "output = decoder_dense(decoder_output)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "\n",
    "# Compile & run training\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
    "# rather than sequences of integers like `decoder_input_data`!\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = pad_sequences([i[0] for i in dataset], maxlen=MAX_LEN, padding=\"post\")\n",
    "decoder_target_data = pad_sequences([[decode(ind) for ind in i[1]] for i in dataset], maxlen=MAX_LEN, padding=\"post\")\n",
    "decoder_input_data = pad_sequences([[0]+i[1][:-1] for i in dataset], maxlen=MAX_LEN, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 15 samples\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.6010 - acc: 0.0577 - val_loss: 2.0878 - val_acc: 0.0513\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.5885 - acc: 0.0577 - val_loss: 2.1316 - val_acc: 0.0410\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.5375 - acc: 0.0659 - val_loss: 2.1756 - val_acc: 0.0410\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4868 - acc: 0.0810 - val_loss: 2.2236 - val_acc: 0.0462\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.4304 - acc: 0.0783 - val_loss: 2.2156 - val_acc: 0.0462\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.3776 - acc: 0.0989 - val_loss: 2.2709 - val_acc: 0.0564\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.3036 - acc: 0.1058 - val_loss: 2.2510 - val_acc: 0.0462\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.2417 - acc: 0.1140 - val_loss: 2.2499 - val_acc: 0.0410\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.1723 - acc: 0.1250 - val_loss: 2.3434 - val_acc: 0.0513\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.1041 - acc: 0.1319 - val_loss: 2.3118 - val_acc: 0.0513\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0393 - acc: 0.1511 - val_loss: 2.4272 - val_acc: 0.0564\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.9816 - acc: 0.1538 - val_loss: 2.3734 - val_acc: 0.0667\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.9248 - acc: 0.1731 - val_loss: 2.4344 - val_acc: 0.0564\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.8648 - acc: 0.1978 - val_loss: 2.4520 - val_acc: 0.0615\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.8001 - acc: 0.2157 - val_loss: 2.4194 - val_acc: 0.0513\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.7568 - acc: 0.2321 - val_loss: 2.4512 - val_acc: 0.0667\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.7028 - acc: 0.2376 - val_loss: 2.4737 - val_acc: 0.0462\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.6479 - acc: 0.2637 - val_loss: 2.4801 - val_acc: 0.0564\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.5920 - acc: 0.2871 - val_loss: 2.5145 - val_acc: 0.0667\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.5538 - acc: 0.2830 - val_loss: 2.4942 - val_acc: 0.0410\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.5133 - acc: 0.3036 - val_loss: 2.5484 - val_acc: 0.0564\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.4804 - acc: 0.3022 - val_loss: 2.5747 - val_acc: 0.0513\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.4508 - acc: 0.3118 - val_loss: 2.5871 - val_acc: 0.0564\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.4199 - acc: 0.3091 - val_loss: 2.6008 - val_acc: 0.0667\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.4038 - acc: 0.3201 - val_loss: 2.6293 - val_acc: 0.0513\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.3809 - acc: 0.3201 - val_loss: 2.6271 - val_acc: 0.0615\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.3547 - acc: 0.3228 - val_loss: 2.6579 - val_acc: 0.0462\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.3382 - acc: 0.3201 - val_loss: 2.7294 - val_acc: 0.0564\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.3204 - acc: 0.3242 - val_loss: 2.6920 - val_acc: 0.0513\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.3045 - acc: 0.3255 - val_loss: 2.7272 - val_acc: 0.0513\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2819 - acc: 0.3338 - val_loss: 2.7394 - val_acc: 0.0513\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2662 - acc: 0.3365 - val_loss: 2.7491 - val_acc: 0.0410\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2593 - acc: 0.3310 - val_loss: 2.7521 - val_acc: 0.0513\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2555 - acc: 0.3297 - val_loss: 2.7892 - val_acc: 0.0513\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2566 - acc: 0.3393 - val_loss: 2.7798 - val_acc: 0.0462\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2526 - acc: 0.3338 - val_loss: 2.8050 - val_acc: 0.0410\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2414 - acc: 0.3310 - val_loss: 2.7812 - val_acc: 0.0513\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2264 - acc: 0.3434 - val_loss: 2.8124 - val_acc: 0.0462\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2125 - acc: 0.3393 - val_loss: 2.8318 - val_acc: 0.0564\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2090 - acc: 0.3393 - val_loss: 2.8195 - val_acc: 0.0564\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2188 - acc: 0.3407 - val_loss: 2.8384 - val_acc: 0.0564\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2333 - acc: 0.3269 - val_loss: 2.8432 - val_acc: 0.0359\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.2171 - acc: 0.3324 - val_loss: 2.8690 - val_acc: 0.0513\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1948 - acc: 0.3448 - val_loss: 2.8441 - val_acc: 0.0462\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1812 - acc: 0.3462 - val_loss: 2.8676 - val_acc: 0.0462\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1686 - acc: 0.3558 - val_loss: 2.8871 - val_acc: 0.0513\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1655 - acc: 0.3599 - val_loss: 2.8894 - val_acc: 0.0462\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1706 - acc: 0.3585 - val_loss: 2.8830 - val_acc: 0.0513\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.1663 - acc: 0.3544 - val_loss: 2.8970 - val_acc: 0.0513\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 0.1597 - acc: 0.3558 - val_loss: 2.9172 - val_acc: 0.0615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2600896e048>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=50,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(HIDDEN_SIZE,))\n",
    "decoder_state_input_c = Input(shape=(HIDDEN_SIZE,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_embeddings_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141, 104, 117, 104, 102,  36,  33,  24,  95,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = pad_sequences([dataset[0][0]], maxlen=MAX_LEN, padding=\"post\")\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_input):\n",
    "        x_pad = pad_sequences([x_input], maxlen=MAX_LEN, padding=\"post\")\n",
    "        target_seq = np.zeros((1, MAX_LEN), dtype='int32')\n",
    "        last_output = None\n",
    "        for i in range(MAX_LEN):\n",
    "            output = model.predict_on_batch([x_pad, target_seq])\n",
    "            sampled_index = np.argmax(output[0, i, :])\n",
    "            target_seq[0, i] = sampled_index\n",
    "            last_output = output\n",
    "        return last_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['что', ',', 'мансур', ',', 'не', 'жарко', 'теперь', 'тебе', '?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Спрашиваю не жарко ему ? . . . выпил выпил сто сто ?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predict(dataset[0][0])\n",
    "answer = [id2word[str(np.argmax(predicted[i][j]))] for i in range(len(predicted)) for j in range(len(predicted[i]))]\n",
    "result_text = \" \".join(answer).capitalize()\n",
    "print([id2word[str(i)] for i in dataset[0][0]])\n",
    "result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тысяча тридцать четвертый .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'В , наша ты принимай тяжелораненого ! ! ? ! ? ! .'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = predict(dataset[3][0])\n",
    "answer = [id2word[str(np.argmax(predicted[i][j]))] for i in range(len(predicted)) for j in range(len(predicted[i]))]\n",
    "result_text = \" \".join(answer).capitalize()\n",
    "print(\" \".join([id2word[str(i)] for i in dataset[3][0]]))\n",
    "result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([141, 104, 117, 104, 102, 36, 33, 24, 95], [92, 104, 102, 36, 76, 33, 95])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
